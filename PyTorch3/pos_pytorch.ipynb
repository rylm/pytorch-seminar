{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "collapsed": true,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Part Of Speech Tagging\n",
    "\n",
    "<img src=https://i.stack.imgur.com/6pdIT.png width=320>\n",
    "\n",
    "Unlike our previous experience with language modelling, this time around we learn the mapping between two different kinds of elements.\n",
    "\n",
    "This setting is common for a range of useful problems:\n",
    "* Speech Recognition - processing human voice into text\n",
    "* Part Of Speech Tagging - for morphology-aware search and as an auxuliary task for most NLP problems\n",
    "* Named Entity Recognition - for chat bots and web crawlers\n",
    "* Protein structure prediction - for bioinformatics\n",
    "\n",
    "Our current guest is part-of-speech tagging. As the name suggests, it's all about converting a sequence of words into a sequence of part-of-speech tags. We'll use a reduced tag set for simplicity:\n",
    "\n",
    "### POS-tags\n",
    "- ADJ - adjective (new, good, high, ...)\n",
    "- ADP - adposition\t(on, of, at, ...)\n",
    "- ADV - adverb\t(really, already, still, ...)\n",
    "- CONJ\t- conjunction\t(and, or, but, ...)\n",
    "- DET - determiner, article\t(the, a, some, ...)\n",
    "- NOUN\t- noun\t(year, home, costs, ...)\n",
    "- NUM - numeral\t(twenty-four, fourth, 1991, ...)\n",
    "- PRT -\tparticle (at, on, out, ...)\n",
    "- PRON - pronoun (he, their, her, ...)\n",
    "- VERB - verb (is, say, told, ...)\n",
    "- .\t- punctuation marks\t(. , ;)\n",
    "- X\t- other\t(ersatz, esprit, dunno, ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "button": false,
    "collapsed": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to /Users/alexajax/nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n",
      "[nltk_data] Downloading package universal_tagset to\n",
      "[nltk_data]     /Users/alexajax/nltk_data...\n",
      "[nltk_data]   Package universal_tagset is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import sys\n",
    "import numpy as np\n",
    "nltk.download('brown')\n",
    "nltk.download('universal_tagset')\n",
    "data = nltk.corpus.brown.tagged_sents(tagset='universal')\n",
    "all_tags = ['#EOS#','#UNK#','ADV', 'NOUN', 'ADP', 'PRON', 'DET', '.', 'PRT', 'VERB', 'X', 'NUM', 'CONJ', 'ADJ']\n",
    "\n",
    "data = np.array([ [(word.lower(),tag) for word,tag in sentence] for sentence in data ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "button": false,
    "collapsed": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexajax/anaconda3/lib/python3.5/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "train_data,test_data = train_test_split(data,test_size=0.25,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "button": false,
    "collapsed": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr><td>NOUN</td><td>ADP</td><td>NOUN</td><td>NOUN</td><td>NOUN</td><td>NOUN</td><td>VERB</td><td>ADV</td><td>VERB</td><td>ADP</td><td>DET</td><td>ADJ</td><td>NOUN</td><td>.</td></tr><td>implementation</td><td>of</td><td>georgia's</td><td>automobile</td><td>title</td><td>law</td><td>was</td><td>also</td><td>recommended</td><td>by</td><td>the</td><td>outgoing</td><td>jury</td><td>.</td><tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table><tr><td>PRON</td><td>VERB</td><td>ADP</td><td>DET</td><td>NOUN</td><td>.</td><td>VERB</td><td>NOUN</td><td>PRT</td><td>VERB</td><td>.</td><td>DET</td><td>NOUN</td><td>.</td></tr><td>it</td><td>urged</td><td>that</td><td>the</td><td>city</td><td>``</td><td>take</td><td>steps</td><td>to</td><td>remedy</td><td>''</td><td>this</td><td>problem</td><td>.</td><tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table><tr><td>NOUN</td><td>VERB</td></tr><td>merger</td><td>proposed</td><tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import HTML, display\n",
    "def draw(sentence):\n",
    "    words,tags = zip(*sentence)\n",
    "    display(HTML('<table><tr>{tags}</tr>{words}<tr></table>'.format(\n",
    "                words = '<td>{}</td>'.format('</td><td>'.join(words)),\n",
    "                tags = '<td>{}</td>'.format('</td><td>'.join(tags)))))\n",
    "    \n",
    "    \n",
    "draw(data[11])\n",
    "draw(data[10])\n",
    "draw(data[7])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "### Building vocabularies\n",
    "\n",
    "Just like before, we have to build a mapping from tokens to integer ids. This time around, our model operates on a word level, processing one word per RNN step. This means we'll have to deal with far larger vocabulary.\n",
    "\n",
    "Luckily for us, we only receive those words as input i.e. we don't have to predict them. This means we can have a large vocabulary for free by using word embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "button": false,
    "collapsed": true,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "word_counts = Counter()\n",
    "for sentence in data:\n",
    "    words,tags = zip(*sentence)\n",
    "    word_counts.update(words)\n",
    "\n",
    "all_words = ['#EOS#','#UNK#']+list(list(zip(*word_counts.most_common(10000)))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "button": false,
    "collapsed": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coverage = 0.92876\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a13f16160>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#let's measure what fraction of data words are in the dictionary\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.hist(list(word_counts.values()),range=[0,1000],bins=50)\n",
    "plt.xlabel(\"Word freqency\")\n",
    "plt.yscale('log')\n",
    "\n",
    "print(\"Coverage = %.5f\"%(float(sum(word_counts[w] for w in all_words)) / sum(word_counts.values())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "button": false,
    "collapsed": true,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "word_to_id = defaultdict(lambda:1, {word:i for i,word in enumerate(all_words)})\n",
    "tag_to_id = {tag:i for i,tag in enumerate(all_tags)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "convert words and tags into fixed-size matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "button": false,
    "collapsed": true,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "def to_matrix(lines,token_to_id,max_len=None,pad=0,dtype='int32',time_major=False):\n",
    "    \"\"\"Converts a list of names into rnn-digestable matrix with paddings added after the end\"\"\"\n",
    "    \n",
    "    max_len = max_len or max(map(len,lines))\n",
    "    matrix = np.empty([len(lines),max_len],dtype)\n",
    "    matrix.fill(pad)\n",
    "\n",
    "    for i in range(len(lines)):\n",
    "        line_ix = list(map(token_to_id.__getitem__,lines[i]))[:max_len]\n",
    "        matrix[i,:len(line_ix)] = line_ix\n",
    "\n",
    "    return matrix.T if time_major else matrix\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "button": false,
    "collapsed": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word ids:\n",
      "[[   2 3069    5    2 2261 1337 4197 2437    3    6   19   26 1068   69\n",
      "     8 2089    6    3    1    3  266   65  342    2    1    3    2  315\n",
      "     1    9   87  216 3351   69 1559    4    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0]\n",
      " [  45   12    8  511 8166    6   60 3259   39    2    1    1    3    2\n",
      "   843    1    3    1    3   10 9976    2    1 3486    9   43    1    1\n",
      "     3    6    2 1048  385   73 4609    3    9    2    1    1 3207    3\n",
      "    12   10    2  856 5301   12    8 8763  121    1    4]\n",
      " [  33   64   26   12  444    7 7088    9    8 3324    3    1 2784    3\n",
      "     2  463  572    2    1    1 1645   12    1    4    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0]]\n",
      "Tag ids:\n",
      "[[ 6  3  4  6  3  3  9  9  7 12  4  5  9  4  6  3 12  7  9  7  9  8  4  6\n",
      "   3  7  6 13  3  4  6  3  9  4  3  7  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0]\n",
      " [ 5  9  6  9  3 12  6  3  7  6 13  3  7  6 13  3  7 13  7  5  9  6  3  3\n",
      "   4  6 13  3  7 12  6  3  6 13  3  7  4  6  3  9  3  7  9  4  6 13  3  9\n",
      "   6  3  2 13  7]\n",
      " [ 4  6  5  9 13  4  3  4  6 13  7 13  3  7  6  3  4  6 13  3  3  9  9  7\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "batch_words,batch_tags = zip(*[zip(*sentence) for sentence in data[-3:]])\n",
    "\n",
    "print(\"Word ids:\")\n",
    "print(to_matrix(batch_words,word_to_id))\n",
    "print(\"Tag ids:\")\n",
    "print(to_matrix(batch_tags,tag_to_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "collapsed": true,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "### Build model\n",
    "\n",
    "Unlike our previous lab, this time we'll focus on a high-level keras interface to recurrent neural networks. It is as simple as you can get with RNN, allbeit somewhat constraining for complex tasks like seq2seq.\n",
    "\n",
    "By default, all keras RNNs apply to a whole sequence of inputs and produce a sequence of hidden states `(return_sequences=True` or just the last hidden state `(return_sequences=False)`. All the recurrence is happening under the hood.\n",
    "\n",
    "At the top of our model we need to apply a Dense layer to each time-step independently. As of now, by default keras.layers.Dense would apply once to all time-steps concatenated. We use __keras.layers.TimeDistributed__ to modify Dense layer so that it would apply across both batch and time axes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "button": false,
    "collapsed": true,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "button": false,
    "collapsed": true,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "class TagNN(nn.Module):\n",
    "    def __init__(self, num_words, num_tags, embedding_size, rnn_size):\n",
    "        super().__init__()\n",
    "        self.emb = nn.Embedding(num_words, embedding_size)\n",
    "        \n",
    "        self.r1 = nn.LSTM(embedding_size, rnn_size, batch_first=True)\n",
    "        self.r2 = nn.LSTM(embedding_size, rnn_size, batch_first=True)\n",
    "        \n",
    "        self.l1 = nn.Linear(2*rnn_size, num_tags)\n",
    "    def forward(self, bx):\n",
    "        emb = self.emb(bx)\n",
    "        emb_inv_idx = torch.arange(emb.size(1)-1, -1, -1).long()\n",
    "        emb_inv = emb[:, emb_inv_idx]\n",
    "        \n",
    "        r2_out = self.r2(emb_inv)[0]\n",
    "        r2_out_inv_idx = torch.arange(r2_out.size(1)-1, -1, -1).long()\n",
    "        r2_out_inv = r2_out[:, r2_out_inv_idx]\n",
    "        \n",
    "        return self.l1(torch.cat([self.r1(emb)[0], r2_out_inv], dim=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "button": false,
    "collapsed": true,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "tag_nn = TagNN(len(all_words), len(tag_to_id), 64, 128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "__Training:__ in this case we don't want to prepare the whole training dataset in advance. The main cause is that the length of every batch depends on the maximum sentence length within the batch. Instead, we'll form batches on the fly using custom generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "button": false,
    "collapsed": true,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "from tqdm import tnrange\n",
    "def generate_batches(sentences, batch_size=32, max_len=None,pad=0):\n",
    "    assert isinstance(sentences,np.ndarray),\"Make sure sentences is q numpy array\"\n",
    "    indices = np.random.permutation(np.arange(len(sentences)))\n",
    "    for start in tnrange(0, len(indices) - 1, batch_size):\n",
    "        batch_indices = indices[start: start + batch_size]\n",
    "        batch_words, batch_tags = [], []\n",
    "        for sent in sentences[batch_indices]:\n",
    "            words, tags = zip(*sent)\n",
    "            batch_words.append(words)\n",
    "            batch_tags.append(tags)\n",
    "\n",
    "        batch_words = to_matrix(batch_words, word_to_id, max_len,pad)\n",
    "        batch_tags = to_matrix(batch_tags, tag_to_id, max_len, pad)\n",
    "        yield batch_words,batch_tags\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "button": false,
    "collapsed": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf31f2e63d42495fa4e1bf18e88a76fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1344), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Shapes: (32, 40) (32, 40)\n"
     ]
    }
   ],
   "source": [
    "bx, by = next(generate_batches(train_data))\n",
    "print(\"Shapes:\", bx.shape, by.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "button": false,
    "collapsed": true,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "bx = torch.tensor(bx, dtype=torch.int64)\n",
    "by = torch.tensor(by, dtype=torch.int64)\n",
    "\n",
    "# apply your model to bx and by\n",
    "\n",
    "by_pred = F.log_softmax(tag_nn(bx), dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "button": false,
    "collapsed": true,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "def to_one_hot(y_tensor, depth=None):\n",
    "    r\"\"\"\n",
    "    Takes integer with n dims and converts it to 1-hot representation with n + 1 dims.\n",
    "    The n+1'st dimension will have zeros everywhere but at y'th index, where it will be equal to 1.\n",
    "    Args:\n",
    "        y: input integer (IntTensor, LongTensor or Variable) of any shape\n",
    "        depth (int):  the size of the one hot dimension\n",
    "    \"\"\"\n",
    "    y_flat = y_tensor.type(torch.LongTensor).view(-1, 1)\n",
    "    depth = depth if depth is not None else int(torch.max(y_flat)) + 1\n",
    "    y_one_hot = torch.zeros(y_flat.size()[0], depth).scatter_(1, y_flat, 1)\n",
    "    y_one_hot = y_one_hot.view(*(tuple(y_tensor.shape) + (-1,)))\n",
    "    return y_one_hot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "We also have to compute test accuracy. The catch is that our input data comes with padding that should not affect accuracy in any way. Therefore, we'll have to write our own function for padding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "button": false,
    "collapsed": true,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "predict_proba = lambda bx: F.softmax(tag_nn(torch.tensor(bx, dtype=torch.int64)), dim=2).detach().numpy()\n",
    "\n",
    "def compute_accuracy(data):\n",
    "    test_words,test_tags = zip(*[zip(*sentence) for sentence in data])\n",
    "    \n",
    "    numerator = 0   # number of correct predictions\n",
    "    denominator = 0 # total number of predictions\n",
    "    \n",
    "    for bx,by in generate_batches(data):\n",
    "        #predict tags of shape [batch,length]    \n",
    "        predicted_tags = predict_proba(bx).argmax(axis=-1)\n",
    "        numerator += np.sum((predicted_tags == by) & (bx != 0))\n",
    "        denominator += np.sum(bx != 0)\n",
    "    \n",
    "    #compute accurary excluding padding\n",
    "    return float(numerator)/denominator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "button": false,
    "collapsed": true,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "tag_nn = TagNN(len(all_words), len(tag_to_id), 64, 128)\n",
    "opt = torch.optim.Adam(tag_nn.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Finally we got to training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "button": false,
    "collapsed": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a1b1c8048>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a84fd11dcc694693a7452592bb319323",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=448), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-f3bcdd15b0f6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompute_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mclear_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-25-605a75b24a16>\u001b[0m in \u001b[0;36mcompute_accuracy\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mbx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mby\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgenerate_batches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;31m#predict tags of shape [batch,length]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mpredicted_tags\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mnumerator\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted_tags\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mby\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbx\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mdenominator\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbx\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-25-605a75b24a16>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(bx)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredict_proba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mbx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtag_nn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcompute_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mtest_words\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_tags\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.5/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-c5e55a550e9f>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, bx)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0memb_inv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0memb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0memb_inv_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mr2_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mr2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memb_inv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mr2_out_inv_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr2_out\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mr2_out_inv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr2_out\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr2_out_inv_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.5/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.5/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    190\u001b[0m             \u001b[0mflat_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflat_weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m         )\n\u001b[0;32m--> 192\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    193\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_packed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPackedSequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.5/site-packages/torch/nn/_functions/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(input, *fargs, **fkwargs)\u001b[0m\n\u001b[1;32m    321\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecorator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 323\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.5/site-packages/torch/nn/_functions/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(input, weight, hidden, batch_sizes)\u001b[0m\n\u001b[1;32m    241\u001b[0m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 243\u001b[0;31m         \u001b[0mnexth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_first\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mvariable_length\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.5/site-packages/torch/nn/_functions/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(input, hidden, weight, batch_sizes)\u001b[0m\n\u001b[1;32m     84\u001b[0m                 \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnum_directions\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m                 \u001b[0mhy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m                 \u001b[0mnext_hidden\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m                 \u001b[0mall_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.5/site-packages/torch/nn/_functions/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(input, hidden, weight, batch_sizes)\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0msteps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreverse\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m             \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m             \u001b[0;31m# hack to handle LSTM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m             \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.5/site-packages/torch/nn/_functions/rnn.py\u001b[0m in \u001b[0;36mLSTMCell\u001b[0;34m(input, hidden, w_ih, w_hh, b_ih, b_hh)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0mcy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mforgetgate\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mcx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mingate\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mcellgate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m     \u001b[0mhy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutgate\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mhy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.5/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mtanh\u001b[0;34m(input)\u001b[0m\n\u001b[1;32m    962\u001b[0m     \u001b[0mSee\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;32mclass\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTanh\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmore\u001b[0m \u001b[0mdetails\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    963\u001b[0m     \"\"\"\n\u001b[0;32m--> 964\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    965\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    966\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "history = []\n",
    "\n",
    "for epoch in range(5):\n",
    "    for bx, by in generate_batches(train_data):\n",
    "        bx = torch.tensor(bx, dtype=torch.int64)\n",
    "        by = torch.tensor(by, dtype=torch.int64)\n",
    "        by_pred = F.log_softmax(tag_nn(bx), dim=2)\n",
    "        loss = (-by_pred*to_one_hot(by, depth=len(all_tags))).sum(dim=2).mean()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "        \n",
    "    history.append(compute_accuracy(test_data))\n",
    "    clear_output(True)\n",
    "    print(\"Epoch: %i, accuracy = %.5f\"%(epoch + 1, history[-1]))\n",
    "    plt.plot(history)\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Measure final accuracy on the whole test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "button": false,
    "collapsed": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "739ce6340e0d4194bbf261a30f914407",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=448), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final accuracy: 0.94126\n"
     ]
    }
   ],
   "source": [
    "acc = compute_accuracy(test_data)\n",
    "print(\"Final accuracy: %.5f\"%acc)\n",
    "\n",
    "assert acc>0.94, \"Sanity check failed. Make sure you didn't tweak hyperparameters too much.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "### Getting all bidirectional\n",
    "\n",
    "Since we're analyzing a full sequence, it's legal for us to look into future words.\n",
    "\n",
    "A simple way to achieve that is to go both directions at once, making a __bidirectional RNN__.\n",
    "\n",
    "Your first task is to use such a layer in POS-tagger."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "### Task II: now go and improve it\n",
    "\n",
    "You guesses it. We're now gonna ask you to come up with a better network.\n",
    "\n",
    "Here's a few tips:\n",
    "\n",
    "* __Go beyond SimpleRNN__: there's `LSTM(Cell)` and `GRU(Cell)`\n",
    "  * You can also use 1D Convolutions (`Conv1D`). They are often as good as recurrent layers but with less overfitting.\n",
    "* __Stack more layers__: if there is a common motif to this course it's about stacking layers\n",
    "  * You can just add recurrent and 1dconv layers on top of one another and keras will understand it\n",
    "  * Just remember that bigger networks may need more epochs to train.\n",
    "  \n",
    "* __Gradient clipping__: If your training isn't as stable as you'd like, try `gradient clipping`\n",
    "  * Which is to say, it's a good idea to watch over your loss curve at each minibatch. Try plotting loss history to see if gradients explode.\n",
    "  \n",
    "* __Regularization__: you can apply dropouts as usual but also in an RNN-specific way\n",
    "  * `nn.Dropout` works fine inbetween RNN layers\n",
    "  \n",
    "* __More words!__: You can obtain greater performance by expanding your model's input dictionary from 5000 to up to every single word!\n",
    "  * Just make sure your model doesn't overfit due to so many parameters.\n",
    "  * Combined with regularizers or pre-trained word-vectors this could be really good cuz right now our model is blind to >5% of words.\n",
    "  \n",
    "* __The most important advice__: don't cram in everything at once!\n",
    "  * If you stuff in a lot of modiffications, some of them almost inevitably gonna be detrimental and you'll never know which of them are.\n",
    "  * Try to instead go in small iterations and record experiment results to guide further search.\n",
    "  \n",
    "There's some advanced stuff waiting at the end of the notebook.\n",
    "  \n",
    "Good hunting!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "collapsed": true,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "<your code here>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "collapsed": true,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "acc = compute_accuracy(<...>, test_data)\n",
    "print(\"\\nFinal accuracy: %.5f\"%acc)\n",
    "\n",
    "if acc >= 0.99:\n",
    "    print(\"Awesome! Sky was the limit and yet you scored even higher! (bonus +2)\")\n",
    "elif acc >= 0.98:\n",
    "    print(\"Excellent! Whatever dark magic you used, it certainly did it's trick. (bonus +1)\")\n",
    "elif acc >= 0.97:\n",
    "    print(\"Well done! (max score)\")\n",
    "elif acc > 0.96:\n",
    "    print(\"Just a few more iterations! (max score - 1)\")\n",
    "else:\n",
    "    print(\"There seems to be something broken in the model. Unless you know what you're doing, try taking bidirectional RNN and adding one enhancement at a time to see where's the problem.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "#### Some advanced stuff\n",
    "Here there are a few more tips on how to improve training that are a bit trickier to impliment. We strongly suggest that you try them _after_ you've got a good initial model.\n",
    "* __Use pre-trained embeddings__: you can use pre-trained weights from [there](http://ahogrammer.com/2017/01/20/the-list-of-pretrained-word-embeddings/) to kickstart your Embedding layer.\n",
    "  * Embedding layer has a matrix W (layer.W) which contains word embeddings for each word in the dictionary. You can just overwrite them with tf.assign.\n",
    "  * When using pre-trained embeddings, pay attention to the fact that model's dictionary is different from your own.\n",
    "  * You may want to switch trainable=False for embedding layer in first few epochs as in regular fine-tuning.  \n",
    "* __More efficient baching__: right now TF spends a lot of time iterating over \"0\"s\n",
    "  * This happens because batch is always padded to the length of a longest sentence\n",
    "  * You can speed things up by pre-generating batches of similar lengths and feeding it with randomly chosen pre-generated batch.\n",
    "  * This technically breaks the i.i.d. assumption, but it works unless you come up with some insane rnn architectures.\n",
    "* __Structured loss functions__: since we're tagging the whole sequence at once, we might as well train our network to do so.\n",
    "  * There's more than one way to do so, but we'd recommend starting with [Conditional Random Fields](http://blog.echen.me/2012/01/03/introduction-to-conditional-random-fields/)\n",
    "  * You could plug CRF as a loss function and still train by backprop. There's even some neat tensorflow [implementation](https://www.tensorflow.org/api_guides/python/contrib.crf) for you.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "collapsed": true,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
